"""Add collection_id foreign key to documents

Revision ID: a1eb74c7c068
Revises: 24bceff4d06d
Create Date: 2025-08-02 23:03:57.570848

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'a1eb74c7c068'
down_revision: Union[str, Sequence[str], None] = '24bceff4d06d'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('data_embeddings_embedding_idx'), table_name='data_embeddings', postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
    op.drop_table('data_embeddings')
    op.drop_index(op.f('data_embeddings_idx_1'), table_name='data_data_embeddings')
    op.drop_table('data_data_embeddings')
    op.alter_column('collections', 'description',
               existing_type=sa.TEXT(),
               type_=sa.String(),
               existing_nullable=True)
    op.drop_index(op.f('idx_collections_vector_db_id'), table_name='collections')
    op.add_column('documents', sa.Column('filename', sa.String(), nullable=False))
    op.add_column('documents', sa.Column('content_type', sa.String(), nullable=False))
    op.add_column('documents', sa.Column('patient_code', sa.String(), nullable=True))
    op.add_column('documents', sa.Column('facility_id', sa.UUID(), nullable=False))
    op.add_column('documents', sa.Column('file_path', sa.String(), nullable=False))
    op.add_column('documents', sa.Column('file_size', sa.Integer(), nullable=False))
    op.add_column('documents', sa.Column('processed', sa.Boolean(), nullable=True))
    op.add_column('documents', sa.Column('document_metadata', sa.JSON(), nullable=True))
    op.alter_column('documents', 'document_type',
               existing_type=sa.VARCHAR(length=100),
               nullable=False)
    op.drop_index(op.f('documents_embedding_idx'), table_name='documents', postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
    op.drop_index(op.f('idx_documents_collection_id'), table_name='documents')
    op.drop_index(op.f('idx_documents_document_type'), table_name='documents')
    op.drop_index(op.f('idx_documents_patient_identifier_id'), table_name='documents')
    op.drop_constraint(op.f('documents_patient_identifier_id_fkey'), 'documents', type_='foreignkey')
    op.create_foreign_key(None, 'documents', 'facilities', ['facility_id'], ['id'])
    op.drop_column('documents', 'sensitivity_level')
    op.drop_column('documents', 'patient_identifier_id')
    op.drop_column('documents', 'content')
    op.drop_column('documents', 'document_category')
    op.drop_column('documents', 'embedding')
    op.drop_column('documents', 'metadata_json')
    op.alter_column('facilities', 'address',
               existing_type=sa.TEXT(),
               type_=sa.String(),
               existing_nullable=True)
    op.drop_index(op.f('idx_facilities_name'), table_name='facilities')
    op.drop_index(op.f('idx_patient_identifiers_facility_id'), table_name='patient_identifiers')
    op.drop_index(op.f('idx_patient_identifiers_patient_code'), table_name='patient_identifiers')
    op.drop_index(op.f('idx_users_email'), table_name='users')
    op.drop_index(op.f('idx_users_username'), table_name='users')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_index(op.f('idx_users_username'), 'users', ['username'], unique=False)
    op.create_index(op.f('idx_users_email'), 'users', ['email'], unique=False)
    op.create_index(op.f('idx_patient_identifiers_patient_code'), 'patient_identifiers', ['patient_code'], unique=False)
    op.create_index(op.f('idx_patient_identifiers_facility_id'), 'patient_identifiers', ['facility_id'], unique=False)
    op.create_index(op.f('idx_facilities_name'), 'facilities', ['name'], unique=False)
    op.alter_column('facilities', 'address',
               existing_type=sa.String(),
               type_=sa.TEXT(),
               existing_nullable=True)
    op.add_column('documents', sa.Column('metadata_json', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('documents', sa.Column('embedding', sa.NullType(), autoincrement=False, nullable=True))
    op.add_column('documents', sa.Column('document_category', sa.VARCHAR(length=100), server_default=sa.text("'clinical'::character varying"), autoincrement=False, nullable=True))
    op.add_column('documents', sa.Column('content', sa.TEXT(), autoincrement=False, nullable=False))
    op.add_column('documents', sa.Column('patient_identifier_id', sa.UUID(), autoincrement=False, nullable=True))
    op.add_column('documents', sa.Column('sensitivity_level', sa.VARCHAR(length=50), server_default=sa.text("'standard'::character varying"), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'documents', type_='foreignkey')
    op.create_foreign_key(op.f('documents_patient_identifier_id_fkey'), 'documents', 'patient_identifiers', ['patient_identifier_id'], ['id'])
    op.create_index(op.f('idx_documents_patient_identifier_id'), 'documents', ['patient_identifier_id'], unique=False)
    op.create_index(op.f('idx_documents_document_type'), 'documents', ['document_type'], unique=False)
    op.create_index(op.f('idx_documents_collection_id'), 'documents', ['collection_id'], unique=False)
    op.create_index(op.f('documents_embedding_idx'), 'documents', ['embedding'], unique=False, postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
    op.alter_column('documents', 'document_type',
               existing_type=sa.VARCHAR(length=100),
               nullable=True)
    op.drop_column('documents', 'document_metadata')
    op.drop_column('documents', 'processed')
    op.drop_column('documents', 'file_size')
    op.drop_column('documents', 'file_path')
    op.drop_column('documents', 'facility_id')
    op.drop_column('documents', 'patient_code')
    op.drop_column('documents', 'content_type')
    op.drop_column('documents', 'filename')
    op.create_index(op.f('idx_collections_vector_db_id'), 'collections', ['vector_db_id'], unique=False)
    op.alter_column('collections', 'description',
               existing_type=sa.String(),
               type_=sa.TEXT(),
               existing_nullable=True)
    op.create_table('data_data_embeddings',
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('text', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('metadata_', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('node_id', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('embedding', sa.NullType(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('data_data_embeddings_pkey'))
    )
    op.create_index(op.f('data_embeddings_idx_1'), 'data_data_embeddings', [sa.literal_column("(metadata_ ->> 'ref_doc_id'::text)")], unique=False)
    op.create_table('data_embeddings',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('text', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('metadata_', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('node_id', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('embedding', sa.NullType(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('data_embeddings_pkey'))
    )
    op.create_index(op.f('data_embeddings_embedding_idx'), 'data_embeddings', ['embedding'], unique=False, postgresql_with={'lists': '100'}, postgresql_using='ivfflat')
    # ### end Alembic commands ###
